## kin simulation
baremetal machine
https://docs.google.com/spreadsheets/d/1CcRQa9WWnkY_3fmGvXb5_IsR1Ik4nWnchxgVGUCz8AA/edit?usp=sharing
usr: sol

putty.exe -ssh sol@145.40.68.91
plink -batch ssh@myserver /etc/backups/do-backup.sh
pscp local_file user@thor.cs.wmich.edu:/home/path_to_the_folder/

# use quote for env varibles
pscp wipe_ledger.sh "sol@%kin2%:/home/sol/"

// gensis commandline argument???
./multinode-demo/setup.sh solana-genesis

 "Starting validator with: ArgsOs"
 Waiting for 80% of activated stake at slot 1 to be in gossip... 

// build all solana
cargo-install-all.sh

// download build from the CI and restart on the validator service
./update edge
/home/sol/.local

// rpc nodes
gcloud compute ssh testnet-kin-rpc-bm-1 --zone=us-east1-b
gcloud compute ssh testnet-kin-rpc-bm-2 --zone=us-east1-b
boot-scripts.sh

// scping files
gcloud compute scp solana-validator testnet-kin-rpc-bm-1:/home/haoran_yi_solana_com/  
gcloud compute scp solana-validator testnet-kin-rpc-bm-2:/home/haoran_yi_solana_com/  

systemd service
// restart service
sudo systemctl daemon-reload
sudo systemctl restart sol
sudo systemctl --no-pager status sol

// config service
sudo systemctl | grep sol
sudo systemctl edit sol
sol@dev-server-ny5:~$ less /etc/systemd/system/sol.service

// check syslog for crash
sudo less /var/log/syslog

// gclound snapshot storage
https://cloud.google.com/storage/docs/gsutil_install#deb
gsutil cp gs://kin-snapshots/genesis/* .
gsutil cp gs://kin-snapshots/snapshot/snapshot-152000-4DBJcbqvTk9UaUabwrTECNPTnZc4CK7kB2pTZjT9jgVu.tar.zst .
gsutil cp gs://kin-snapshots/bin/solana-validator .

## service config file 
sol@dev-server-ny5:~$ cat /etc/systemd/system/sol.service
[Unit]
Description=Solana Validator
After=network.target
Wants=solana-sys-tuner

[Service]
Type=simple
Restart=always
RestartSec=1
User=sol
LimitNOFILE=500000
StartLimitIntervalSec=0
LogRateLimitIntervalSec=0
ExecStart=/home/sol/bin/validator.sh

[Install]
WantedBy=multi-user.target

## ledger tool command
~/solana-ledger-tool --ledger /home/sol/ledger/ create-snapshot 131030 >& 131030.log
~/solana-ledger-tool --ledger /home/sol/ledger/ verify --allow-dead-slots --accounts-db-skip-shrink --no-os-memory-stats-reporting --halt-at-slot 131040

## remove account by deactivate a feature
./src/solana/target/release/solana-ledger-tool --ledger /home/sol/ledger/ create-snapshot 574346 --remove-account capRxUrBjNkkCpjrJxPGfPaWijB7q3JoDfsWXAnt46r --hard-fork 574346

// pattern to grep
grep "bank_frozen" 131040.1.10.da11.log
grep "bank frozen" 131040.1.10.da11.log
grep "bank frozen\|without_index" 131040.1.10.da11.log
grep "bank frozen\|without_index: slot" 131040.1.10.da11.log
grep "bank frozen\|without_index: slot" 131040.kin.log
grep 131040 solana-validator-AYJDiE3wgw5eanU4qJ4qfkB8vrHVEiBMTqXLbA9hUTaW.log
grep " bank frozen: 131040 hash:" solana-validator-AYJDiE3wgw5eanU4qJ4qfkB8vrHVEiBMTqXLbA9hUTaW.log
grep "bank frozen\|without_index: slot" 131040.kin.log
grep "failed to match" solana-validator-AYJDiE3wgw5eanU4qJ4qfkB8vrHVEiBMTqXLbA9hUTaW.log


~/solana-ledger-tool --ledger ~/131039_ledger/ copy --starting-slot 131039 --ending-slot 131040 --target-db ~/ledger
~/solana-ledger-tool --ledger /home/sol/ledger/ verify --allow-dead-slots --accounts-db-skip-shrink --halt-at-slot 131040 >& 131040.after_copy.log

restart 2022/5/23:
Successfully created snapshot for slot 99273, hash 7LqrSQiZQHqaQWAoyWL86zxLCrKG1jh8vBeYwNBp3GzT: /home/sol/ledger/snapshot-99273-9XQgP53GH2bqHLvKGfAePHPAN9a1tNwYRo4s9EzoMfRw.tar.zst
Shred version: 8321

when kin-sim account capped for about 750M?
`cap_accounts_data_len` will cap the total size of accounts data to 50G. The
following patch will remove that cap.
diff --git a/runtime/src/bank.rs b/runtime/src/bank.rs
index 20585ca1dd..4ee9e4cc82 100644
--- a/runtime/src/bank.rs
+++ b/runtime/src/bank.rs
@@ -7465,7 +7465,7 @@ impl Bank {
         }

         if new_feature_activations.contains(&feature_set::cap_accounts_data_len::id()) {
-            const ACCOUNTS_DATA_LEN: u64 = 50_000_000_000;
+            const ACCOUNTS_DATA_LEN: u64 = u64::MAX;
             self.accounts_data_size_initial = ACCOUNTS_DATA_LEN;
         }

file://snapshots_backup/no_cap/snapshot-99273-9XQgP53GH2bqHLvKGfAePHPAN9a1tNwYRo4s9EzoMfRw.tar.zst
gsutil cp gs://kin-snapshots/bank-hash/snapshot-99273-9XQgP53GH2bqHLvKGfAePHPAN9a1tNwYRo4s9EzoMfRw.tar.zst .

restart 2022/5/31
total lamport mismatch
~/solana-ledger-tool --ledger /home/sol/ledger/ accounts 
~/solana-ledger-tool --ledger /home/sol/ledger/ capitalization 

syslog rotate
sol@testnet-kin-rpc-bm-2:~$ ls -l /var/log/syslog*
-rw-r----- 1 syslog adm 1680188 May 31 12:48 /var/log/syslog
-rw-r----- 1 syslog adm 3248702 May 31 00:00 /var/log/syslog.1
-rw-r----- 1 syslog adm  772941 May 30 00:00 /var/log/syslog.2.gz
-rw-r----- 1 syslog adm  642416 May 29 00:00 /var/log/syslog.3.gz
-rw-r----- 1 syslog adm  723526 May 28 00:00 /var/log/syslog.4.gz
-rw-r----- 1 syslog adm  668958 May 27 00:00 /var/log/syslog.5.gz
-rw-r----- 1 syslog adm  579668 May 26 00:00 /var/log/syslog.6.gz
-rw-r----- 1 syslog adm  540877 May 25 00:00 /var/log/syslog.7.gz

bm2 restart 2022/6/3
snapshot-1708971-5pvJvFbMKwSF3bLmgwqwTLc68AXPTEzR6ZoCRbfeCbaR.tar.zst
bank_hash: 3o6C44n9vxcb6V9R2u7sntH8KxEy5M2g1CaejZCCNhLh

bm1/bm2 restart 2022/6/5
sol@kin-validator-am6-1:~$ grep 2010782 bank_hash.txt
[2022-06-06T00:03:04.239824954Z INFO  solana_runtime::accounts_background_service] Took bank snapshot. snapshot type: Some(IncrementalSnapshot(1994201)), slot: 2010782, accounts hash: 11111111111111111111111111111111, bank hash: FJb267uzBL9G9KejcoGxX7mv2DCWgA2ALQP4HUrecHin

2022/6/14
kin resart with 6/3 snapshot and kin_jun12_2022
rm solana-validator && gsutil cp gs://kin-snapshots/bin/solana-validator.2022.6.12 solana-validator && chmod u+x 
        WAIT_FOR_SUPERMAJORITY=1708971
        EXPECTED_BANK_HASH=3o6C44n9vxcb6V9R2u7sntH8KxEy5M2g1CaejZCCNhLh


2022/6/15
dev2

26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE

ledger at epoch boundary
da11 has a ledger that contains a mnb epoch crossing +/- 200 slots:
~/src/solana/target/release/solana-ledger-tool verify --ledger /mnt/nvme1n1/ledger_rewards/
dev1    4CTAFwtdoKd8b3W3HrjV9rhm2eZz4ES2NNfrapaRBZyj    145.40.77.67    dev-server-da11

2022/7/13
- select log between 15:03 - 15:05
    // next: skip abc
    awk '/abc/{flag=1;next}/mno/{flag=0}flag' file
    // skip the end
    awk '/2022-07-13T15:03/{flag=1}/2022-07-13T15:05/{flag=0}flag' log
- print inclusive
    awk '/abc/{a=1}/mno/{print;a=0}a' file
    awk '/abc/{a=1} a; /mno/{a=0}' file


2022/7/18
==========
attach to running process
>> gdb -p PID


2022/7/29
=========
Debug and fixed a deadlock issue. What I learned:
1. use map to trace lock/unlock with file:line:thread_id
2. look for new code and walk up the stack, find that if there is any self
   locking which happens  on the call stack. This often happens on the same
   thread. It is easy and most likely to be ignored. In fact, this is actually
   where the bug is. Especially when the bug is very reproducible.
3. use PubKey for logging and grep pubkey for contentsion.
4. use try_lock/try_read/try_write when in deadlock to figure out what we are
   blocking on.

2022/8/3
=========
solana-validator, when passing `--wait-for-supermajority`,
`--expected-bank-hash`, even without `--no-snapshot-fetch`, it woun't download
remote snapshot.  To start rpc node, use `boot-scripts-fetch-snapshot.sh`.



mainnet keys
"host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE'  #dev2
"host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE'  #dev1
"host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE'  #dev4
"host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE'



from(bucket: "mainnet-beta")
  |> range(start: 2022-08-14T23:55:00Z, stop: 2022-08-15T00:01:00Z)
  |> filter(fn: (r) => r["_measurement"] == "accounts_db_store_timings")
  |> filter(fn: (r) => r["_field"] == "read_only_accounts_cache_misses" or r["_field"] == "read_only_accounts_cache_hits" or r["_field"] == "read_only_accounts_cache_evicts")
  |> filter(fn: (r) => r["host_id"] == "26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE")
  |> aggregateWindow(every: 1s, fn: max, createEmpty: false)
  |> yield(name: "mean")

// cache entry size
from(bucket: "mainnet-beta")
  |> range(start: 2022-08-14T23:55:00Z, stop: 2022-08-15T00:01:00Z)
  |> filter(fn: (r) => r["_measurement"] == "accounts_db_store_timings")
  |> filter(fn: (r) => r["_field"] == "read_only_accounts_cache_entries")
  |> filter(fn: (r) => r["host_id"] == "26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE")
  |> aggregateWindow(every: 1s, fn: max, createEmpty: false)
  |> yield(name: "max")

cache entry flattern around 650K, 550K

// influx exmaples
https://www.sqlpac.com/en/documents/influxdb-flux-language-advanced-features.html


2023/1/4
----------
Setup systemd service

sol@testnet-kin-accounts-client-bm-2:~$ sudo systemctl cat kin.client
# /etc/systemd/system/kin.client.service
[Unit]
Description=Kin Account Bench Client

[Service]
Type=simple
Restart=always
RestartSec=1
User=sol
WorkingDirectory=/home/sol
ExecStart=/home/sol/run-client.sh

[Install]
WantedBy=multi-user.target

401  sudo systemctl daemon-reload
408  sudo systemctl start kin.client.service
402  sudo systemctl status kin.client
411  sudo journalctl -xe

2023/1/17
----------
Increase disk space for gcloud machines
1. edit the attached disk to increase its size
2. resize the file system and partitions with the new large disk
    - gather info
        $ sudo du -Th # find size and usage for your disks
        $ sudo lsblk  # find the device names for your disks
        For example, /dev/sda is mounted to /, type is ext4 
    - resize partition
        $ sudo parted /dev/sda
        (parted) resizepart
        (Partition number) 1
        (Warning ...) Yes
        (End) 100%
        (parted) quit
    - read the new partition table
        $ sudo partprobe /dev/sda
    - extend the file system
        $ sudo resize2fs /dev/sda1
        $ sudo xfs_growfs -d /
3. verify the disk has been extended
    $ df -Th 
https://cloud.google.com/compute/docs/disks/resize-persistent-disk?hl=en-au&_ga=2.257649867.-1961129437.1646147137

2023/1/19
----------
Starting a new network fresh from genesis (kin-sim)

# create genesis
    $ target/release/solana-genesis --max-genesis-archive-unpacked-size 1073741824 --enable-warmup-epochs --bootstrap-validator /home/sol/identity/validator-identity-am6-1.json /home/sol/identity/validator-vote-account-am6-1.json /home/sol/identity/validator-stake-account-am6-1.json --bpf-program TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA BPFLoader2111111111111111111111111111111111 spl_token-3.5.0.so --bpf-program Memo1UhkJRfHyvLMcVucJwxXeuD728EqVDDwQDxFMNo BPFLoader1111111111111111111111111111111111 spl_memo-1.0.0.so --bpf-program MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr BPFLoader2111111111111111111111111111111111 spl_memo-3.0.0.so --bpf-program ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL BPFLoader2111111111111111111111111111111111 spl_associated-token-account-1.1.2.so --bpf-program Feat1YXHhH6t1juaWF74WLcfv4XoNocjXA6sPWHNgAse BPFLoader2111111111111111111111111111111111 spl_feature-proposal-1.0.0.so --ledger /home/sol/ledger --faucet-pubkey /home/sol/identity/faucet.json --faucet-lamports 500000000000000000 --hashes-per-tick auto --cluster-type development

# start faucet
    $ ~/src/solana/target/release/solana-faucet --keypair identity/faucet.json

# bootstrap validator

# startup other validator

# start client

# use `solana` cli to monitor the network
    $ watch solana -u m block  # mainnet block
    $ solana-watchtower --validator-identity <YOUR VALIDATOR IDENTITY>

# how to interact with the network 
    1. with `solana` cli to create account, airdrop/transfer tokens 
        https://docs.solana.com/cli/transfer-tokens
    2. or with json rpc
        https://docs.solana.com/integrations/exchange
curl localhost:8899 -X POST -H "Content-Type: application/json" -d '{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "getMinimumBalanceForRentExemption",
  "params":[0]
}'

# Result
{"jsonrpc":"2.0","result":890880,"id":1}
    3. use spl-token to manage user defined token
        https://spl.solana.com/token


comments:
1. it may take a while for the non-leader nodes to download
    gensis/snapshot from bootstrap nodes.
2. incorrect program id error in client program?

# genesis and mint token

1. option 1: create genesis from google cluster (not working)
// from /net dir of solana repo/commit

    ./gce.sh create -n 3 -c 0 -p testnet-dev-kin-haoran -P --dedicated  --validator-boot-disk-size-gb 3600 --self-destruct-hours 0 -z us-east1-b --custom-machine-type "--custom-cpu 64 --min-cpu-platform Intel%20Skylake --custom-vm-type n1 --custom-memory 256GB"

    ./net.sh start --internal-nodes-stake-lamports 1000000000000 --extra-primordial-stakes 3 --faucet-lamports 500000000000000000 --slots-per-epoch 432000

# this commands works with 4 equal stakes (copied from gce cluster, don't use.  see kin_genesis_gen_with_4_staked_nodes.sh for genesis)
solana-genesis 
    --bootstrap-validator-stake-lamports 1000000000000 
    --faucet-lamports 500000000000000000 
    --slots-per-epoch 432000 
    --bootstrap-validator BStdMoTsjSzT1Qhgf52ciKMVDUwh6dnYgwYKMUat3H4s H9uTwVX2WdgauG8HoSfEC6Vh6MfUoR3Vu2FQrfXuxiDH 87ZCi24nE 6V73reyT9Uu1vniLX58FAhHBgN55pXt3aZU 
    --bootstrap-validator 9kKh4CrVSRLNijzk9KVUHg6QSsAHPKzX5aXdJ9NkWatq 5W5KkhwJp2rkJ8n8qNbs3RZFxDaDB7pKHRHGfebFDQDk E1cjeMpKengWzsQ2kDtVYECxkJHsSe51pCMzsuQxUsZt 
    --bootstrap-validator 6uzGKe3AgJgiiGqd23GVzoseyT9ovkDi4gnBchbghcUD FfMUFKEG4zM6S2rxHWbt8AHBpEZZsxQbUMSzL5BJCzQ7 Gso1FJXogYg7qEUsYQZAHLtha7g7ba6wANpmJWUU5tzB 
    --max-genesis-archive-unpacked-size 1073741824 
    --enable-warmup-epochs 
    --bootstrap-validator /home/solana/solana/net/../config/bootstrap-validator/identity.json /home/solana/solana/net/../config/bootstrap-validator/vote-account.json /home/solana/solana/net/../config/bootstrap-validator/stake-account.json 
    --bpf-program TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA BPFLoader2111111111111111111111111111111111 spl_token-3.5.0.so 
    --bpf-program Memo1UhkJRfHyvLMcVucJwxXeuD728EqVDDwQDxFMNo BPFLoader1111111111111111111111111111111111 spl_memo-1.0.0.so 
    --bpf-program MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr BPFLoader2111111111111111111111111111111111 spl_memo-3.0.0.so 
    --bpf-program ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL BPFLoader2111111111111111111111111111111111 spl_associated-token-account-1.1.2.so 
    --bpf-program Feat1YXHhH6t1juaWF74WLcfv4XoNocjXA6sPWHNgAse BPFLoader2111111111111111111111111111111111 spl_feature-proposal-1.0.0.so 
    --ledger /home/solana/solana/net/../config/bootstrap-validator 
    --faucet-pubkey /home/solana/solana/net/../config/faucet.json 
    --hashes-per-tick auto --cluster-type development

It seems that genesis from ./net.sh is broken?
After create ledger on the bootstrap node, ledger-tool fails to extract the bank hash from snap of slot1. And can't start the cluster? Is that expected?
haoran_yi_solana_com@testnet-dev-kin-haoran-bootstrap-validator:~$  ls /home/solana/solana/config/bootstrap-validator/
accounts.ledger-tool  genesis.bin  genesis.tar.bz2  identity.json  rocksdb  snapshot-1-WiowSLurQoZrBXfmwyBb84k1mbFh3sHBLq41Anrx5t4.tar.zst  snapshot.ledger-tool  stake-account.json  vote-account.json
++ solana-ledger-tool -l config/bootstrap-validator bank-hash
[2023-01-20T02:34:52.423038671Z INFO  solana_ledger_tool] solana-ledger-tool 1.15.0 (src:devbuild; feat:2221197578)
[2023-01-20T02:34:52.423884939Z INFO  solana_ledger::blockstore] Maximum open file descriptors: 1000000
[2023-01-20T02:34:52.423901857Z INFO  solana_ledger::blockstore] Opening database at "/home/solana/solana/config/bootstrap-validator/rocksdb"
[2023-01-20T02:34:52.423913781Z INFO  solana_ledger::blockstore_db] Disabling rocksdb's automatic compactions...
[2023-01-20T02:34:52.429892189Z INFO  solana_ledger::blockstore_db] Opening Rocks with secondary (read only) access at: "/home/solana/solana/config/bootstrap-validator/rocksdb/solana-secondary"
[2023-01-20T02:34:52.429906849Z INFO  solana_ledger::blockstore_db] This secondary access could temporarily degrade other accesses, such as by solana-validator
[2023-01-20T02:34:52.446842048Z INFO  solana_ledger::blockstore] "/home/solana/solana/config/bootstrap-validator/rocksdb" open took 22ms
Unable to load bank forks at slot 0 due to disconnected blocks.
+ bankHash=
(edited)


2. use the solana-genesis command directly (this commands only have stake on one node, and that bootstrap node is always the leader so it only have tpu)
    $ target/release/solana-genesis --max-genesis-archive-unpacked-size 1073741824 --enable-warmup-epochs --bootstrap-validator /home/sol/identity/validator-identity-am6-1.json /home/sol/identity/validator-vote-account-am6-1.json /home/sol/identity/validator-stake-account-am6-1.json --bpf-program TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA BPFLoader2111111111111111111111111111111111 spl_token-3.5.0.so --bpf-program Memo1UhkJRfHyvLMcVucJwxXeuD728EqVDDwQDxFMNo BPFLoader1111111111111111111111111111111111 spl_memo-1.0.0.so --bpf-program MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr BPFLoader2111111111111111111111111111111111 spl_memo-3.0.0.so --bpf-program ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL BPFLoader2111111111111111111111111111111111 spl_associated-token-account-1.1.2.so --bpf-program Feat1YXHhH6t1juaWF74WLcfv4XoNocjXA6sPWHNgAse BPFLoader2111111111111111111111111111111111 spl_feature-proposal-1.0.0.so --ledger /home/sol/ledger --faucet-pubkey /home/sol/identity/faucet.json --faucet-lamports 500000000000000000 --hashes-per-tick auto --cluster-type development


3. add the mint token
I added spl-* program. I think the missing part is the token is not added.
    $sol@testnet-kin-rpc-bm-1:~$ spl-token accounts -u l
    None
So I try to use spl-token create-token to create token to mint. (edited) 
but I get the insufficent fund error.
    sol@testnet-kin-rpc-bm-1:~$ spl-token create-token -u l
    Creating token DbMmTMoucui4Hw1a3C7T9SQm6skaw3kYyFzdxEEpdCV
    Fee payer, 7JcmM6TFZMkcDkZe6RKVkGaWwN5dXciGC4fa3RxvqQc9, has insufficient balance: 0.0014716 required, 0 available

When I try to do an air drop, it fails too.

    sol@testnet-kin-rpc-bm-1:~$ solana airdrop 1 -u l
    Requesting airdrop of 1 SOL
    Error: airdrop request failed. This can happen when the rate limit is reached.


4. after spinning up the faucet process, then it works
    $ nohup ~/src/solana/target/release/solana-faucet --keypair identity/faucet.json &>faucet.log &

    $ sol@testnet-kin-rpc-bm-1:~$ solana airdrop 1 -u l
    Requesting airdrop of 1 SOL

    Signature: bqhWhRUXr5hUfYGUeHwZAbPKzeNnPoyifz8He9UJervJD6TgTK4bZ2AA995tmdgiuQFiKw6E8wWxgPDVLUgShVH

    1 SOL
    $ sol@testnet-kin-rpc-bm-1:~$ spl-token create-token -u l
    Creating token Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt

    Signature: 64B1S4BbmcVyxRPMs6NzvGZvKy5P6TRpL9gRqu6YAuKrNZDhVxJpxDttq4BzqKC2K2XJXqHmnXEWafeBDWKXTrMj
yeah. I created the token. Now kin-sim start working.

5. After create about 4M accounts, the clients starts failing again. Do airdrop 1M sol for all clients
    $ for x in accounts-cluster-id*; do ./solana-keygen pubkey $x; done > client_pubkey.txt
    $ cat client_pubkey.txt | while read line; do solana airdrop -u l 1000000 $line; done

6. more spl-token commands

sol@testnet-kin-rpc-bm-1:~$ spl-token balance Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
    Could not find token account 75hJoh8vtuXSzeKmqHLZPsdGErV66ESYwPn6pRGg8Wxt
    sol@testnet-kin-rpc-bm-1:~$ spl-token create-account Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
    Creating account 75hJoh8vtuXSzeKmqHLZPsdGErV66ESYwPn6pRGg8Wxt

    Signature: 2TtUrSgnj6sbtaSD2adqd4a9aDRA3McDbPyVsTaGrJ3574Fv5N64eFRs6B7qnnDZKcbBjFhLcjp4x5cH6qo6yDzQ

sol@testnet-kin-rpc-bm-1:~$ spl-token balance Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
    0

sol@testnet-kin-rpc-bm-1:~$ spl-token supply Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
    0

sol@testnet-kin-rpc-bm-1:~$ spl-token mint Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt 100 -u l
    Minting 100 tokens
      Token: Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt
      Recipient: 75hJoh8vtuXSzeKmqHLZPsdGErV66ESYwPn6pRGg8Wxt

    Signature: pfWoSKGQmfYmCjKtwqQiPVf1V6cNj23hv1Vq59MErytZQSU9hVEs3j8xzsAatSeHRe5uZaA8wC5TmzmNHcUAzsz

sol@testnet-kin-rpc-bm-1:~$ spl-token balance Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
100

sol@testnet-kin-rpc-bm-1:~$ spl-token supply Dx2KVx97kD95Av66EUuuiaTSrXG78zwk8zXNanzEpkPt -u l
100

2023/1/25
----------
It many take a while for the rpc node to catch up, i.e. to pass healthy check.
During the catch up, the client will not be able to add transactions.

rpc_health.rs::RpcHealth::startup_verification_complete, this is set when
load_bankforks completed.

$ solana-validator --ledger ~ledger/ monitor

2023/1/26
----------
/tmp folder filled up when running ledger-tool create-snapshot

2023/2/25
----------
mainnet down
    - turbine stopped working
    - retransmit and repair lots of traffic
    - block time --> concensus failure, no more progress of the network
consensus rainbow from ryoqun
https://codepen.io/ryoqun/full/JjNbeyE
load a yaml file (which contains the query). code_pen.yaml

2023/4/4
----------
Test influx DB datapoint submission
    export INFLUX_DATABASE=testnet-dev-kin-bm
    export INFLUX_USERNAME=scratch_writer
    export INFLUX_PASSWORD=topsecret
    ./metrics-write-datapoint.sh "testnet-deploy net-config-begin=1"

2023/4/7
----------
rust-anlayzer vscode swith from stable to nightly 
- it doesn't honor the toolchain settings on the environment
- To make the change, edit the extension settings in vscode (i.e. setting.json)
    { "rust-analyzer.server.extraEnv": { "RUSTUP_TOOLCHAIN": "stable" } }

2023/4/14
----------
redeem with store contend on accounts db --> slow
therefore gather and store in one batch --> fast


2023/4/19
----------
comamnd to create new genesis (4-way stake)
>> solana-genesis --bootstrap-validator-stake-lamports 1000000000000 --faucet-lamports 500000000000000000 --slots-per-epoch 432000 --bootstrap-validator /home/sol/identity/validator-identity-am6-1.json /home/sol/identity/validator-vote-account-am6-1.json /home/sol/identity/validator-stake-account-am6-1.json --bootstrap-validator Edfkf9gpC7KpnkNdKRPmseCtkE1zY8fUVRJMbiLYKKdK PmXohrohcmtKdeeeYygU4q9wSxujSJLmdVBEbmHhyXa Hij7dbmLSK5fj4Qwo9zM4wqPti28ZYLJLG3oU5M181f7 --bootstrap-validator 2k31vk7hPiu2T9fJzuunc6tmaE57P7wt6tFoGK5A7k47 DJuHQCQrvPRYhNsqTFyvfEEpzypHdBibeidkL5VqSsCx AokbnmuQJ9uCNSen6rW5R9NHkRd43xURknKcy3JTD3mi --bootstrap-validator 3cVWsRiTXD99BXNhzXs7Gkm3YBhCDrMQWnLern8B7TrD Dou12zNcGLyDeLcxeRGzQ2xBx1orSWg9AKyuWBgfKREp 7jbYYZHc4wG4pf8E4r3VXEeJFHxAKSb7aJwrNa7mA2zK --max-genesis-archive-unpacked-size 1073741824 --enable-warmup-epochs --bpf-program TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA BPFLoader2111111111111111111111111111111111 spl_token-3.5.0.so --bpf-program Memo1UhkJRfHyvLMcVucJwxXeuD728EqVDDwQDxFMNo BPFLoader1111111111111111111111111111111111 spl_memo-1.0.0.so --bpf-program MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr BPFLoader2111111111111111111111111111111111 spl_memo-3.0.0.so --bpf-program ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL BPFLoader2111111111111111111111111111111111 spl_associated-token-account-1.1.2.so --bpf-program Feat1YXHhH6t1juaWF74WLcfv4XoNocjXA6sPWHNgAse BPFLoader2111111111111111111111111111111111 spl_feature-proposal-1.0.0.so --ledger /home/sol/ledger --faucet-pubkey /home/sol/identiy/faucet.json --hashes-per-tick auto --cluster-type development

>> ./stage/bin/solana-ledger-tool create-snapshot --ledger ~/ledger 1

new genesis and snapshot
Genesis hash: FUMidJRmNSY3bsBRE6eVnbcaTq2mV2XsD5DUrjQa7iHP

snapshot-1-GdkQfTVrgf9Z8N5LoCBy3Mzbf5oxDvyJBwzdwX9fZBF2.tar.zst
snapshot-hash: 2A3cHk5nmkJdX7QPDDhfdhYB1HYwHmdFPkeddfdMmJ6M

>> rm -rf ledger
>> mkdir ledger
>> gsutil cp -r gs://kin-snapshots/kin-genesis-2023-04-19 .
>> cp kin-genesis-2023-04-19/* ledger/
>> echo 2A3cHk5nmkJdX7QPDDhfdhYB1HYwHmdFPkeddfdMmJ6M >>start_slot_info.txt

1. rpc node stuck on slot 1 because no shreds are flowing. 
    - to fix, wait for a snapshot and restart rpc with snapshot fetching.
    - something is wrong with repair, empty shred, stuck?


2023/4/21
----------
download snapshot for mainet-beta
>> gsutil ls -l  gs://mainnet-beta-ledger-us-ny5/189212973/hourly

2023/5/5
----------
rust abi test require nightly on cargo because of RUSTC_WITH_SPECIALIZATION
feature.

2023/5/5
----------
docker setup on solana devbox
2012  docker
2014  groups sol
2015  grep docker /etc/group
2018  sudo usermod -a -G docker sol
2019  groups sol

2023/5/16
----------
RocksDB is an embeded key-value storage. lower-level storage used by MySQL,
MongoDB, TiDB.
- Column Family
    - each key-value pair is associated with one column family
    - logically partition of the database
    - share write-ahead log, but don't share memtable and table files
        - by sharing write-ahead logs --> automic write
        - by separating memtable and table files --> independent cloumn faimly
          configuration and fast deleting

- Remarks (flush all column families regularly)

Every time a single Column Family is flushed, we create a new WAL (write-ahead
log). All new writes to all Column Families go to the new WAL. However, we
still can't delete the old WAL since it contains live data from other Column
Families. We can delete the old WAL only when all Column Families have been
flushed and all data contained in that WAL persisted in table files. This
created some interesting implementation details and will create interesting
tuning requirements. Make sure to tune your RocksDB such that all column
families are **regularly** flushed. Also, take a look at
Options::max_total_wal_size, which can be configured such that stale column
families are automatically flushed.         

- APIs
    rocksdb::DB::open()  // open database instance
    db_instance.cf_handle()  // open column family
    instance.put(key, value)  // save
    let val : Vec<u8> = instance.get(key)  // read
    instance.put_cf(cf, key, value)  // save
    let val : Vec<u8> = instance.get_cf(cf, key)  // read

- use serde to serialize/deserialize json to work with rocks

- Rocks DB tuning guide
    - Block size
    - Write buffer
    - Compression
    - Cache
    - Key Layout (frequent access keys are in the same blocks)
    - Filter: bloom filter (reduce disk read at the cost of more memory)
    - Checksums
    - Compaction
        - sorted run/recent-old levels/block by key
        - leveled (one run per level)
        - tiered (multiple sort run --> one run in next level)
    - Approximate sizes
    - Environment
    - Purging WAL files
https://github.com/facebook/rocksdb/wiki/Setup-Options-and-Basic-Tuning
https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide

- design philosophy 
    
The design goal was for disks and insert/update/delete intensive tables that
get more **writes** than **reads**. Transactional logging (history tables) is
one example. The LSM was shown to use less IO capacity than a B-Tree for
making changes durable and that was a big deal when the cost of IOPs was a
significant fraction of the system cost.  The LSM uses less disk IO capacity
than a B-Tree for two reasons: It does multi-page writes rather than single
page writes so the seek latency is amortized over N pages (maybe N=64). Assume
a disk can do either 32 1MB transfers/s or 128 4kb transfers/s. Then
multi-page block IO throughput is 64x faster.  When sized appropriately, it
does a page write per M modified rows while a B-Tree in the worst case (for
their example) does a page write per modified row.
    - buffering (in-memory) and then flushing (block writes 64x faster)
leveled vs tiered
    - one run vs multiple run
    - one run + range partition == multiple runs in one level.

2023/7/6
----------
solana rpc default port is 8899.
setup reverse proxy for 80, which will route 80 to 8899.
    /etc/haproxy/*.config
check for port
    sudo ss -lptn 'sport = :80'
    sudo lsof -n -i :80 | grep LISTEN
    sudo netstat -nlp | grep :80

to run solana-validator as a process, you will need to follow this:   
https://docs.solana.com/running-validator/validator-start

2023/7/6
----------
reverse proxy vs forward proxy
    - forward proxy is like vpn, hide client ip
    - reverse proxy is to hide the backend server
        - ngnx
        - haproxy
        - typical example: forward 80 to internal serve port i.e. 8899

2023/8/22
----------
commands to adjust nofiles limits on the box
    sudo vim /etc/sysctl.d/21-solana-validator.conf
    cat /proc/sys/fs/file-max
    sudo vim /etc/security/limits.conf
    sudo vim /etc/hostname
    sudo vim /etc/hosts
    sudo reboot
    cd /etc/systemd/system
    sudo vim sol.service
    ls
    sudo rm -rf solana-warehouse-upload.service
    cat sol.service
    vim kin.client.service
    sudo vim kin.client.service
    sudo systemctl daemon-reload
    cd ~
    ls
    sudo vim /etc/hosts
    sudo vim /etc/hostname
    sudo reboot
https://www.tecmint.com/increase-set-open-file-limits-in-linux/    

2023/8/25
----------
On sort:
    - quicksort is unstable, no extra memory 
    - merge sort is stable, need about n/2 extra memory
glidesort    
    - create_runs
    - partition left eq, right eq
    - interleave loops (superscalar)

2023/9/20
----------
current tests:
cherry pick hash dedup vec for pop: 
    hyi/pop_2023_9_20 @pop4

sol@147.28.146.229
    hash_dedup_vec@mnb https://github.com/solana-labs/solana/pull/33246

sol@145.40.69.17
    hash_dedup_linkedlist@mnb https://github.com/solana-labs/solana/pull/33215

cd ~/src/solana/validator && git reset --hard HEAD && git fetch jwash && git checkout jwash/sp15_linked_list_remove_debugging && ../cargo build --release && ~/stop && cp ~/src/solana/target/release/solana-validator /home/sol/.local/share/solana/install/active_release/bin/solana-validator && ~/restart

2023/10/6
---------
syslog for debugging
    $ dmesg -T
    $ sudo less /var/log/syslog
    $ journalctl -u sol

2023/11/10
---------
Select log in range
- grep log by data range (simple but not robust)
    > sed -n "/2023-11-10T12:25/,/2023-11-10T12:35/p" solana-validator.log > a.log
    - print lines from patten1 match till pattern2 match

- use regex
    > sed -E '/2021-02-10 (08:[0-5][0-9]:[0-5][0-9]|09:00:00)/!d' /log/infile
    > grep -E '2021-02-10 (08:[0-5][0-9]:[0-5][0-9]|09:00:00)' /log/infile
    > awk '/2021-02-10 (08:[0-5][0-9]:[0-5][0-9]|09:00:00)/' /log/infile

- use awk scripts (w. datatime calculation)
> awk -v start='2021-02-10 08:00:00' -v end='2021-02-10 08:24:36' -v q="'" '
BEGIN{
    st="date -d" q start q " +%s"; st |getline start; close(st);
    ed="date -d" q end   q " +%s"; ed |getline end;   close(ed)
}
{ dt=$1" "$2; epoch="date -d" q dt q " +%s"; epoch |getline dt; close(epoch) };
(dt>=start && dt<=end)' infile

> awk -v start='2021-02-10 08:00:00' -v end='2021-02-10 08:24:36' '
 BEGIN{ gsub(/[:-]/," ", start); gsub(/[:-]/," ", end) }
      { dt=$1" "$2; gsub(/[:-]/," ", dt) }
 mktime(dt)>=mktime(start) && mktime(dt)<=mktime(end)' infile

2023/11/30
----------
> source ci/rust-version.sh
> ci/docker-run.sh $rust_stable_docker_image ci/stable/run-local-cluster-partially.sh 1 2

- kill a docker run
sol@dev-equinix-washington-5:~/src/solana$ docker stop $(docker ps -q)
a7c88566a86d


2024/1/3
---------
Consensus Fork Choice
  - 43 - 44 (x) - 45 (x) - 47
      \
       44' - 45' - 50

last vote is on 47. 44/45 are ancestor but marked invalid due to duplicates. 
when switching to 43, it will give an error DuplicatedAncestor. 
This is because there is no point to rollback and vote on 43. In replay, it
will have special handling to continue buiding on the alternative fork 44'...
This is in contrast to switch failure where reply continue to build blocks on
the last vote slot.


TODO
2023/8/30 -- to compare
    - dev2 deployed scan-opt code  26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE (very limited diskspace)
    - dev1 deployed scan-base      4CTAFwtdoKd8b3W3HrjV9rhm2eZz4ES2NNfrapaRBZyj
    - hy1                          9ffnCrMEtWQPggdAoMLB15JUVN144m19s6NChwKpoitu 
    - hy2                          4WPtkxR3ThXX86vMP9TEZyVN52Bk3jZBKM5dxyqYv8Pe
    "host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE' or "host_id"='4CTAFwtdoKd8b3W3HrjV9rhm2eZz4ES2NNfrapaRBZyj'
    ("host_id"='26EqJ47BBf6r4fXSfPdmop4yJLuK2YZ5pbGCkM4bvMgE' or "host_id"='4CTAFwtdoKd8b3W3HrjV9rhm2eZz4ES2NNfrapaRBZyj')
compare shrink timing with new unqiue by btreemap    

hash dedup
    ~/stage/bin/solana-ledger-tool verify -l ~/ledger --halt-at-slot 212990773 --run-final-accounts-hash-calculation >c 2>&1
    grep calculate_accounts_hash_from_storages b | awk '{for(i=1; i<=NF; i++) if (0 != index($i, "=")) {print($i)}}' | column -ts "="
generate_index


storage_size_min=233,472i storage_size_quartile_1=294,912i storage_size_quartile_2=311,296i storage_size_quartile_3=339,968i storage_size_max=201,850,880i storage_size_avg=358,451i

2023/12/1
- work on deprecate usage of account `executable` member for transaction loading
    - debug crashes caused by this change on mainnet
- take over jeff's fix for large ancient appendvec creation fix
- run kin-sim to test jeff's new changes for skip-rewrites and ancient appendvec pack/append algorithms
- code reviews for prs

2024/1/10
---------
* elf verify happens with
Executable::load()
elf.rs --> load_with_parser()
         --> Executable::relocate()
         --> for all relocation symbols check for syscalls

* solana bpf build toolchain
    C - sbf.mk
    rust - cargo-build-sbf (binary), --> calls "cargo build", sdk/sbf/scripts/dump.sh ... (spawn a process to call the shell/or program.

* GNU make file
    conditional
    define directive
    functions: $foreach, $eval, $patsub ...

2024/1/17
---------
Rpc log disappear? 
The issue is due to logroate misconfig. 
Two parts:
- logrotate configure is specific to the file, send USR1 to sol.service
    sol@pop-net-sv15-4:~$ cat /etc/logrotate.d/sol
    /home/sol/logs/solana-validator.log {
      daily
      rotate 7
      missingok
      postrotate
        systemctl kill -s USR1 sol.service
      endscript
    }
- inside validator we handle USR1 by recreating the log


2024/1/30
---------
- program id instrument for runtime
diff --git a/program-runtime/src/message_processor.rs b/program-runtime/src/message_processor.rs
index a428cf930e..b5462abc00 100644
--- a/program-runtime/src/message_processor.rs
+++ b/program-runtime/src/message_processor.rs
@@ -135,6 +135,7 @@ impl MessageProcessor {
             } else {
                 let mut time = Measure::start("execute_instruction");
                 let mut compute_units_consumed = 0;
+                println!("haoran {} {:?}", program_id, instruction);
                 let result = invoke_context.process_instruction(
                     &instruction.data,
                     &instruction_accounts,

- vote stats debug
diff --git a/programs/vote/src/vote_processor.rs b/programs/vote/src/vote_processor.rs
index 3bf4e1a67c..9386f62387 100644
--- a/programs/vote/src/vote_processor.rs
+++ b/programs/vote/src/vote_processor.rs
@@ -110,7 +110,10 @@ declare_process_instruction!(Entrypoint, DEFAULT_COMPUTE_UNITS, |invoke_context|
     }

     let signers = instruction_context.get_signers(transaction_context)?;
-    match limited_deserialize(data)? {
+
+    let vv = limited_deserialize(data)?;
+    println!("haoran vv {:?}", vv);
+    match vv {
         VoteInstruction::InitializeAccount(vote_init) => {
             let rent = get_sysvar_with_account_check::rent(invoke_context, instruction_context, 1)?;
             if !rent.is_exempt(me.get_lamports(), me.get_data().len()) {

2024/1/31
---------
Problem don't serialize executable account, executable account have emtpy
data.
>> That is because we concat the machine code (text section) into the read only section during ELF loading
https://github.com/solana-labs/rbpf/blob/179a0f94b68ae0bef892b214750a54448d61b1be/src/elf.rs#L653
".text" section is borrowed by elf ro secion. If we don't serialize executable
accounts, then the borrowed ref will be invalid.
borrow when the data is contiguous. non-contiguous data then copy.
-- knowledge of linker script and elf. manipulate secion, region in elf.

2024/2/7
---------
1. Debugging blocks with solana-ledger-tool commands (dump block info)
    > 2003  solana-ledger-tool blockstore slot 246239968
    > 2004  solana-ledger-tool blockstore slot 246239968 -v
    > 2005  solana-ledger-tool blockstore slot 246239968 -vv
2. Dump onchain program
    > solana -um account HiNWYQeJRupTmk19YmevS6ydpQjTn8zcdhQtcQRNgKMJ > dump.txt
    > solana -um program dump HiNWYQeJRupTmk19YmevS6ydpQjTn8zcdhQtcQRNgKMJ dump.so
    > llvm-objdump -S --no-show-raw-insn  dump.so > dump.txt // dissemble

2024/2/12
---------
Duplicate block problem - multiple block for the same slot
  - due to the limitation we only store one block per slot 
  - solution: dump correct block and ask for another version of the block by
    repair (sampling of the network)
  - to determine which blocks are voted, need to add a new info - hash of the
    block into the vote.

GraphQL
  - auto aggregate the simple queries into a batch to return the set of data
    together to provide the data for UI apps
  - libary for parsing input -> syntax tree then write your own aggregator.

2024/2/13
---------
jito-lab (60% of the stake is running jito client, mostly like the big exchange
nodes are running jito client)
  - special banking stage
      - relayer: send tranaction to block packer to simulate transaction and
        pick transaction that give better MEV (tips) and send to block packer
      - block packer: simulate tranaction and generate blocks, atomic
        transaction batch execution (A/B/C...) 
          - pack mulitple transactions into one transactions ([A,B,C])
      - shred-streamer: pull shred stream directly from other jito staked nodes
  - nodes that run jito will get MEV on top of rewards
work flow
- tx (validator/TPU disabled) -> relayer (filter, dedup) -> block engine (TX
pool) -> searcher (bundle) -> block engine -> valdiator (TX)
  - relayer hold the tx for 200ms before forwarding
  - validator pays 5% of the tips recived from the transaction forward by block engine
Presentation
  https://drive.google.com/file/d/1mLQMGnKUh7RhOSOtLoXIpHhmAjwwO30Q/view
  - modify TPU stage (reolay service), now running on block_engine, searcher service auction, 
  - tips collection and distribution
- banking stage
    - fetch: allocate buffer for incoming transaction packets
    - banking: select the packet from the buffer to execute and pack them into entry (poh clock record, multi-thread banking execution)
    - broadcast entries via turbine to validators
    - the banking/select/pack and broadcast are where jito variant comes in 


2024/2/13
---------
Example how to run test-validator: 
https://github.com/solana-labs/solana/security/advisories/GHSA-r6hw-7rch-5fx9

# 100 is chosen to have faster epochs to quickly observe the issue at epoch boundaries
$ cargo run --bin solana-test-validator -- --slots-per-epoch 100

# wait until the test validator is running and then run the following commands sequentially
$ cargo run --bin solana  -- create-stake-account ./test-ledger/validator-keypair.json 10 -k ./test-ledger/faucet-keypair.json -ul
$ cargo run --bin solana  -- delegate-stake ./test-ledger/validator-keypair.json ./test-ledger/vote-account-keypair.json -k ./test-ledger/faucet-keypair.json -ul

# Then watch the log until the validator panics
# Repeat the process with `VERIFY_REWARD_LAMPORT = false` to see the capitalization mismatch panic

2024/3/5
---------
How run rust-gdb to debug a test?
1. First find the test executable from 'cargo test'. 
2. The run rust-gdb.
    'rust-gdb --args /home/sol/src/solana/target/debug/deps/solana_core-6d9536717513b64c  consensus::test::test_check_vote_threshold_without_votes --exact --nocapture'

- solana vote tower
    - A stack of vote, each element in the stack (slot, confirmation_count). 
    - When a new element is pushed into the stack, the confirmation_count++,
      which means lockout is doubled.
    - Check vote threshold for 'slot_x': Go to the history offset to the vote
      stack, ie 8, tower[8], 8 vote pased. Look for percentage of stake at
      that slot, compare it with total stake, threshold ie 0.66. Then vote
      'slot_x'.
    - Current scheme is to wait on stack offset 8, stop until it receives
      0.66. If it never reaches 0.66 before stack[8] expires then switch forks
    - lockout: simulate a vote on this 'slot', if the vote stack contains any
      slot that's not in the ancestor of 'slot', then 'slot' is considered
      lockout.
- consensus params: 
    - vote threshold depth 8
    - vote threshold: 0.67
    - switch fork: 0.38
    - duplicate confirm: 1-0.38-0.1=0.52     

How to search text in putty command window?
Copy all the text to a file then search in the file with grep etc.

2024/3/5
---------
On rust clap cli for `solana`

1. clap.value_name() is a placeholder only used for display help message. Not
used actually in ArgMatches. In ArgMatches, what get use is what put in
`with_name(xxx)`.

2. How does feature activate subcommand fee_payer get populated and how does it
get default to client keypair?

If the fee_payer argument is missing, then insert wallet_id as the first
account (fee paying account) in the signers. 
[code](https://github.com/solana-labs/solana/blob/9b1243ee4cd13b2bd0f3b5d18bb38ebd39b024b2/clap-utils/src/keypair.rs#L252)

3. Rust clap help ordering?
See fn display_order()
https://docs.rs/clap/latest/clap/struct.Arg.html#method.help

Args with a lower value will be displayed first in the help message. Those
with the same display order will be sorted.

Args are automatically assigned a display order based on the order they are
added to the Command. Overriding this is helpful when the order arguments are
added in isn't the same as the display order, whether in one-off cases or to
automatically sort arguments.

NOTE: This setting is ignored for positional arguments which are always
displayed in index order.

To change, see Command::next_display_order.

Note: Add Arg in reverse order, ie Command.arg(C).arg(B).arg(A) ...  
    so that help will be displayed in A|B|C order.

2024/3/7
---------
How to turn off beep sound of vim/nvim?
Turn off bell sound in putty terminal settings. vim config to turn off bell
sound didn't work with nvim.

AstroNvim Setup 
  1. install from neovim release 
    https://github.com/neovim/neovim/blob/master/INSTALL.md)
  2. create a config file
    ~/.config/nvim/init.lua (or init.vim old vim scripts)
  3. config is organized in Lua modules
    - in lua code, 
        call vim command and functions (vim.cmd(xxx))
        set vim variables (vim.g.xxx, vim.b.xxx)
        set vim options (vim.opt.xxx)
        create mappings (vim.keymap.set(xxx))
        create autocommands (vim.api.nvim_create_autocmd(xxx))
        group autocommands (vim.api.nvim_create_augroup(xxx))
  4. Astro Nvim
        git clone https://github.com/AstroNvim/AstroNvim ~/.config/nvim
        - user_example
        git clone https://github.com/<your_user>/<your_repository> ~/.config/nvim/lua/user
        - lua/xxx on 'runtimepath' is like vim's 'autoload' mechanism
            - put user lua config if folder lua and init.lua load them with
              'require(xxx)'
  5. Astro Nvim
        :LspInstall rust 
        :TSInstall rust
        :Lazy check|update|clean|sync
    - install nerd font
        - doesn't work with putty terminal!
        - instead disable 'icon' in nvim 
            - /user/init.lua options.g.icon_enabled=false
  6. Code completion and hover to see document (Shift+k) is very useful
    - default key mapping is very useful
    - in code complete preview window, use C-d/C-u to scroll.
  7 key mappings
    - leaderkey = space
    - leader f - fuzzy file finder, C-j, C-k to scroll up file
        - C-u/C-d to scroll preview of file
        - in escape mode, h,l to navigate text, j,k to navigate result (telescope)
        - <leader> fw live grep mode 
    - leader gg git action
    - coding
        - Tab/C-space to auto complete, C-e to close, K to show type of symbol
        - gT go to typedef, C-o go back, gI to to implementation, 
          gd jump to symbol def, 
          gr jump to references, 
          gl bring up to error popup, gl again to jump into the popup
            ]d [d  nevigate buffers
        - leader l to bring up code action
            <leader> l r rename
            <leader> l f foramt
            <leader> l a action
            <leader> l L codelens run (however, not supported in rust lsp!)
        - F7 bring up the floating window
        - <leader> S s save session
        - <leader> S . load session
        - mouse supports too!
            - Ctrl-click to jump

Today, I gave a second try for 'nvim' and find out that AstroVim is very good.
So, finally nvim is usable on both windows and linux. It could be a
replacement for VScode and vim. Yah!
On windows, use `nvim-qt`. Need to install NerdFront.            

neovim lua module
    - `init.vim` or init.lua
    - `plugin/xxx`  autorun at startup
    - `lua/xxx` for file loaded on demand
        - `lua/foo/init.lua`  require(xxx) to load the folder
        - use `pcall()` to load module and catch error
    - lua concept
        - tables: python like objects
        - closures: EVERY scope is a closure, function, module, do block etc.
        - coroutines: generator, cooperative multithreading

2024/3/7
---------
Solana network statistics and dashboard. 
    https://analytics.topledger.xyz/solana/public/dashboards/kynZmbwYHB6mqf3DOXGQVFO1Xsff0x154iJpoXeK
    https://dune.com/browse/dashboards?q=solana

2024/3/8
---------
PartialEq vs. Eq. in Rust
Eq is more strict than PartialEq in that A == A. example float.NaN != float.NaN. 
To implemnt Eq, implement PartialEq and add empty trait Eq.

TODO
port vote/stake program changes
https://github.com/solana-labs/solana/pull/27715/files#diff-ab7997cf6770a6fae7b258e433b5dd8c33afa30431eab212552bc7f2b7b38db1


